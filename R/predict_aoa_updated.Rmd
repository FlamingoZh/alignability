---
title: "Predict AoA"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r load-libraries, message = FALSE, warning = FALSE}
library(data.table)
library(tidyverse)
library(here)
library(janitor)
library(glue)
library(tidymodels)
library(vip)
library(ggthemes)
library(finetune)
library(SHAPforxgboost)

theme_set(theme_few(base_size = 14))

knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE)
```

```{r load-aoas}
noun_aoas <- read_delim(here("../data/processed/aoa/kuperman_noun_aoa.txt"),
                       col_names = c("word", "aoa"),
                       show_col_types = FALSE) %>%
  mutate(category = "noun")

verb_aoas <- read_delim(here("../data/processed/aoa/kuperman_verb_aoa.txt"),
                       col_names = c("word", "aoa"),
                       show_col_types = FALSE) %>%
  mutate(category = "verb")

all_aoas <- bind_rows(noun_aoas, verb_aoas)
```


```{r load-other-measures}
freqs <- map_dfr(c("noun", "verb"),
             ~read_delim(here(glue("../data/processed/childes_{.x}_freq.txt")),
                         show_col_types = FALSE) %>% 
               rename(word = gloss, frequency = count) %>%
               mutate(category = .x))

vis_variance <- map_dfr(c("noun", "verb"),
             ~read_delim(
               here(glue("../data/processed/variance/v_variance_{.x}_concept_least20_swav_bert_20.txt")),
                       col_names = c("word", "vis_variance"),
               show_col_types = FALSE) %>%
               mutate(category = .x))


lang_variance <- map_dfr(c("noun", "verb"),
             ~read_delim(
               here(glue("../data/processed/variance/l_variance_{.x}_concept_least20_swav_bert_20.txt")),
                       col_names = c("word", "lang_variance"),
               show_col_types = FALSE) %>%
               mutate(category = .x))

# 
# alignments <- map_dfr(c("noun", "verb"),
#              ~read_delim(here(glue("data/{.x}_alignment_score_least10.txt")),
#                        col_names = c("word", "alignment")) %>%
#                mutate(category = .x))

all_data <- all_aoas %>%
  left_join(freqs, by = c("word", "category")) %>%
  left_join(vis_variance, by = c("word", "category")) %>%
  left_join(lang_variance, by = c("word", "category")) %>%
  na.omit()
#  left_join(alignments, by = c("word", "category")) %>%
 # left_join(cds, by = "word")
```

```{r splits}
d_split <- initial_split(all_data, strata = category)
d_train <- training(d_split)
d_test <- testing(d_split)

d_folds <- vfold_cv(d_train, strata = category)

d_folds
```

```{r rec}
d_rec <-
  recipe(aoa ~ frequency + vis_variance + lang_variance, 
         data = d_train) %>%
  step_log(aoa, frequency) %>%
  step_sqrt(lang_variance)
  #update_role(word, new_role = "id")
 
d_prep <- prep(d_rec)
bake(d_prep, new_data = NULL)
```

```{r spec}
xgb_spec <- boost_tree(
    trees = tune(),
    mtry = tune(),
    min_n = tune(),
    learn_rate = 0.01## step size
) %>% 
  set_engine("xgboost") %>% 
  set_mode("regression")

xgb_wf <- workflow(d_rec, xgb_spec)
xgb_wf

```


```{r res}
doParallel::registerDoParallel()

xgb_rs <-
  tune_race_anova(
    xgb_wf,
    d_folds,
    grid = 20,
    metrics = metric_set(rmse),
    control = control_race(verbose_elim = TRUE)
  )

xgb_rs
```

```{r}
plot_race(xgb_rs)
show_best(xgb_rs)
```

```{r}
xgb_last <-
  xgb_wf %>%
  finalize_workflow(select_best(xgb_rs, "rmse")) %>%
  last_fit(d_split)

xgb_last
```

```{r}
xgb_fit <- extract_fit_parsnip(xgb_last)
vip(xgb_fit, geom = "point", num_features = 12)
```

```{r}
d_shap <-
  shap.prep(
    xgb_model = extract_fit_engine(xgb_fit),
    X_train = bake(d_prep,
      has_role("predictor"),
      new_data = NULL,
      composition = "matrix"
    )
  )

shap.plot.summary(d_shap)
```
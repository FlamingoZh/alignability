---
title: "Predict AoA"
output: html_document
editor_options:
  chunk_output_type: console
---

```{r load-libraries, message = FALSE, warning = FALSE}
library(data.table)
library(tidyverse)
library(here)
library(janitor)
library(glue)
library(tidymodels)
library(vip)
library(ggthemes)
library(finetune)
library(SHAPforxgboost)
library(tidyboot)

theme_set(theme_few(base_size = 14))

knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE)
```

```{r load-aoas-and-freqs}
noun_aoas <- read_delim(here("../data/processed/aoa/kuperman_noun_aoa.txt"),
                       col_names = c("word", "aoa"),
                       show_col_types = FALSE) %>%
  mutate(category = "noun")

verb_aoas <- read_delim(here("../data/processed/aoa/kuperman_verb_aoa.txt"),
                       col_names = c("word", "aoa"),
                       show_col_types = FALSE) %>%
  mutate(category = "verb")

all_aoas <- bind_rows(noun_aoas, verb_aoas)

freqs <- map_dfr(c("noun", "verb"),
             ~read_delim(here(glue("../data/processed/childes_{.x}_freq.txt")),
                         show_col_types = FALSE) %>%
               rename(word = gloss, frequency = count) %>%
               mutate(category = .x))

```

```{r load-unimodal}
read_unimodal_file <- function(category, measure, mode) {
  read_delim(here(glue("../data/processed/{measure}/{mode}_{measure}_{category}_concept_least20_swav_bert_20.txt")),
             col_names = c("word", "value"),
             show_col_types = FALSE)
}

unimodal_data <- expand_grid(category = c("noun", "verb"),
            measure = c("variance", "distinctness"),
            mode = c("l", "v")) %>%
  unite(type, category, measure, mode, remove = FALSE) %>%
  group_by(type) %>%
  nest() %>%
  mutate(data = map(data, ~read_unimodal_file(.$category, .$measure, .$mode))) %>%
  unnest(cols = c(data)) %>%
  separate(type, into = c("category", "measure", "mode")) %>%
  unite(measure, mode, measure)

words <- unimodal_data %>%
  filter(measure == "l_variance") %>%
  select(category, word)
```

```{r load-similarities}
read_multimodal_file <- function(in_category, mode) {
  col_names <- words %>%
    filter(category == in_category) %>% 
    pull(word)
  
  sim_mat <- fread(here(glue("../data/processed/similarity_matrix/{mode}_sim_mat_{in_category}_ll_swav_bert_20.txt")), header = FALSE, col.names = col_names) %>%
    mutate(word1 = col_names) %>%
    as_tibble() %>%
    pivot_longer(cols = -word1, names_to = "word2", values_to = "sim") %>%
    filter(word1 != word2)
}

similarities <- expand_grid(category = c("noun", "verb"),
            mode = c("l", "v")) %>%
  unite(type, category, mode, remove = FALSE) %>%
  group_by(type) %>%
  nest() %>%
  mutate(data = map(data, ~read_multimodal_file(.$category, .$mode))) %>%
  unnest(cols = c(data)) %>%
  separate(type, into = c("category", "mode"))
```

```{r make_model_data}
aoa_and_freqs <- all_aoas %>%
  left_join(freqs, by = c("word", "category")) %>%
  na.omit()

unimodal_measures <- aoa_and_freqs %>%
  left_join(unimodal_data, by = c("category", "word")) %>%
  pivot_wider(names_from = "measure", values_from = "value")

alignments <- aoa_and_freqs %>%
  left_join(similarities, by = c("category", "word" = "word1")) %>%
  inner_join(select(aoa_and_freqs, "word", "category"), 
             by = c("category", "word2" = "word")) %>%
  pivot_wider(names_from = "mode", values_from = "sim") %>%
  group_by(word, category, aoa, frequency) %>%
  summarise(alignment = cor(l, v, method = "spearman"))

all_data <- left_join(unimodal_measures, alignments,
                      by = c("word", "category", "aoa", "frequency"))
```

```{r splits}
d_split <- initial_split(all_data, strata = category)
d_train <- training(d_split)
d_test <- testing(d_split)

d_folds <- vfold_cv(d_train, strata = category)

d_folds
```

```{r rec}
d_rec <-
  recipe(aoa ~ .,
         data = d_train) %>%
  step_log(aoa, frequency, l_distinctness, v_distinctness) %>%
  step_sqrt(l_variance, v_variance) %>%
  step_dummy(category) %>%
  update_role(word, new_role = "id")

d_prep <- prep(d_rec)
bake(d_prep, new_data = NULL)
```

```{r spec}
xgb_spec <- boost_tree(
    trees = tune(),
    mtry = tune(),
    min_n = tune(),
    learn_rate = 0.01## step size
) %>%
  set_engine("xgboost") %>%
  set_mode("regression")

xgb_wf <- workflow(d_rec, xgb_spec)
xgb_wf

```


```{r res}
doParallel::registerDoParallel()

xgb_rs <-
  tune_race_anova(
    xgb_wf,
    d_folds,
    grid = 20,
    metrics = metric_set(rmse),
    control = control_race(verbose_elim = TRUE)
  )

xgb_rs
```

```{r}
plot_race(xgb_rs)
show_best(xgb_rs)
```

```{r}
xgb_last <-
  xgb_wf %>%
  finalize_workflow(select_best(xgb_rs, "rmse")) %>%
  last_fit(d_split)

xgb_last
```

```{r}
xgb_fit <- extract_fit_parsnip(xgb_last)
vip(xgb_fit, geom = "point", num_features = 12)
```

```{r}
d_shap <-
  shap.prep(
    xgb_model = extract_fit_engine(xgb_fit),
    X_train = bake(d_prep,
      has_role("predictor"),
      new_data = NULL,
      composition = "matrix"
    )
  ) %>%
  as_tibble()


d_shap %>%
  group_by(variable) %>%
  summarise(cor = cor(value, rfvalue))

shap.plot.summary(d_shap)
```

```{r}
d_shap %>%
  as_tibble() %>%
  mutate(value = abs(value)) %>%
  group_by(variable) %>%
  tidyboot_mean(value) %>%
  ungroup() %>%
  ggplot(aes(x = variable, y = empirical_stat)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) +
  coord_flip()
```

```{r}
shap.plot.dependence(d_shap, x = "frequency", color_feature = "category_verb")
shap.plot.dependence(d_shap, x = "l_variance", color_feature = "category_verb")
shap.plot.dependence(d_shap, x = "alignment", color_feature = "category_verb")

shap_int <- shap.prep.interaction(
  xgb_model = extract_fit_engine(xgb_fit),
    X_train = bake(d_prep,
      has_role("predictor"),
      new_data = NULL,
      composition = "matrix"
    ))

shap.plot.dependence(data_long = d_shap,
                           data_int = shap_int,
                           x= "frequency",
                           y = "category_verb", 
                           color_feature = "category_verb")
```